From r-help-bounces@stat.math.ethz.ch  Fri May 11 10:50:42 2007
Return-Path: <r-help-bounces@stat.math.ethz.ch>
Received: from hypatia.math.ethz.ch (hypatia.math.ethz.ch [129.132.145.15])
	by flax9.uwaterloo.ca (8.12.8/8.12.5) with ESMTP id l4BEofqD024335
	for <ktwarwic@flax9.uwaterloo.ca>; Fri, 11 May 2007 10:50:42 -0400
Received: from hypatia.math.ethz.ch (hypatia [129.132.145.15])
	by hypatia.math.ethz.ch (8.13.6/8.13.6) with ESMTP id l4BEo7TD014321;
	Fri, 11 May 2007 16:50:25 +0200
X-Spam-Checker-Version: SpamAssassin 3.1.8 (2007-02-13) on hypatia.math.ethz.ch
X-Spam-Level: 
X-Spam-Status: No, score=0.7 required=5.0 tests=AWL, BAYES_50, FUZZY_AMBIEN,
	HTML_30_40, HTML_MESSAGE autolearn=no version=3.1.8
Received: from wr-out-0506.google.com (wr-out-0506.google.com [64.233.184.237])
	by hypatia.math.ethz.ch (8.13.6/8.13.6) with ESMTP id l4BEnmH7014050
	for <r-help@stat.math.ethz.ch>; Fri, 11 May 2007 16:49:50 +0200
Received: by wr-out-0506.google.com with SMTP id i21so1056275wra
	for <r-help@stat.math.ethz.ch>; Fri, 11 May 2007 07:49:47 -0700 (PDT)
Received: by 10.114.74.1 with SMTP id w1mr961893waa.1178894985907;
	Fri, 11 May 2007 07:49:45 -0700 (PDT)
Received: by 10.114.147.16 with HTTP; Fri, 11 May 2007 07:49:45 -0700 (PDT)
Message-ID: <dff718fc0705110749v7f1790ddh19ea748f8f3fb50f@mail.gmail.com>
Date: Fri, 11 May 2007 22:49:45 +0800
From: "=?GB2312?B?wO6/ob3c?=" <klijunjie@gmail.com>
To: r-help@stat.math.ethz.ch
MIME-Version: 1.0
X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
Content-Disposition: inline
Subject: [R] model seleciton by leave-one-out cross-validation
X-BeenThere: r-help@stat.math.ethz.ch
X-Mailman-Version: 2.1.9
Precedence: list
List-Id: "Main R Mailing List: Primary help" <r-help.stat.math.ethz.ch>
List-Unsubscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
	<mailto:r-help-request@stat.math.ethz.ch?subject=unsubscribe>
List-Archive: <https://stat.ethz.ch/pipermail/r-help>
List-Post: <mailto:r-help@stat.math.ethz.ch>
List-Help: <mailto:r-help-request@stat.math.ethz.ch?subject=help>
List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
	<mailto:r-help-request@stat.math.ethz.ch?subject=subscribe>
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: 7bit
Sender: r-help-bounces@stat.math.ethz.ch
Errors-To: r-help-bounces@stat.math.ethz.ch

Hi, all

When I am using mle.cv(wle), I find a interesting problem: I can't do
leave-one-out cross-validation with mle.cv(wle). I will illustrate the
problem as following:

> xx=matrix(rnorm(20*3),ncol=3)
> bb=c(1,2,0)
> yy=xx%*%bb+rnorm(20,0,0.001)+0
> summary(mle.cv(yy~xx,split=nrow(xx)-1,monte.carlo=2*nrow(xx),verbose=T),
num.max=1)[[1]]
mle.cv: dimension of the split subsample set to default value =  9
 (Intercept)          xx1          xx2          xx3           cv
0.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.292513e-06


So does anybody know how to do linear model selection by leave-one-out
cross-validation? I've written one function, but it runs toooooo slow~~~

Thanks firstly

This is my super slow function:


####################
## function: rec.comb
## input: vec -- vector
## output: all possible combination from the elements of vec
####################
rec.comb=function(vec)
{
  if(length(vec)==0){list(NULL)
  }else { tmp=rec.comb(vec[-1])
    tmp2=sapply(tmp,function(x)c(vec[1],x))
    c(tmp,tmp2)
  }
}

####################
## function: CV1glm--CV1 using K fold CV
## input: y -- response vector; x -- predictors without intercept
## output: the vector whether each predictor should be selected. E.g.
 (0,1,0,1) means no intecept while var1 and var3 should be selected
####################
CV1glm=function(y,x){
 n.var=ncol(x)
 n=nrow(x)
 comb=rec.comb(1: (n.var))
 n.comb=length(comb)
 pe=c()

 data=data.frame(y=y)
 glm=glm(y~1,data=data)
 pe[1]=cv.glm(data,glm)$delta[1]
 for(i in 2:n.comb){
  data=data.frame(y=y,x=x[,comb[[i]]])
  glm=glm(y~.,data=data)
  pe[i]=cv.glm(data,glm)$delta[1]
 }
 pe1=c() ####################################without intercept
 pe1[1]=Inf
 for(i in 2:n.comb){
  data=data.frame(y=y,x=x[,comb[[i]]])
  glm=glm(y~.-1,data=data)
  pe1[i]=cv.glm(data,glm)$delta[1]
 }

 var=rep(0,n.var)
 if(min(pe)<min(pe1)){
  int=1
  var[comb[[which(pe==min(pe))]]]=1
 }else{
  int=0
  var[comb[[which(pe1==min(pe1))]]]=1
 }
 c(int,var)
}



-- 
Junjie Li,                  klijunjie@gmail.com
Undergranduate in DEP of Tsinghua University,

	[[alternative HTML version deleted]]

______________________________________________
R-help@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

