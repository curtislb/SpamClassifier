From r-help-bounces@stat.math.ethz.ch  Tue May  8 08:18:14 2007
Return-Path: <r-help-bounces@stat.math.ethz.ch>
Received: from hypatia.math.ethz.ch (hypatia.math.ethz.ch [129.132.145.15])
	by flax9.uwaterloo.ca (8.12.8/8.12.5) with ESMTP id l48CI7qD014979
	for <ktwarwic@flax9.uwaterloo.ca>; Tue, 8 May 2007 08:18:08 -0400
Received: from hypatia.math.ethz.ch (hypatia [129.132.145.15])
	by hypatia.math.ethz.ch (8.13.6/8.13.6) with ESMTP id l48CH3nS017113;
	Tue, 8 May 2007 14:17:14 +0200
X-Spam-Checker-Version: SpamAssassin 3.1.8 (2007-02-13) on hypatia.math.ethz.ch
X-Spam-Level: 
X-Spam-Status: No, score=-0.8 required=5.0 tests=AWL,
	BAYES_50 autolearn=no version=3.1.8
Received: from relay3.mail.ox.ac.uk (relay3.mail.ox.ac.uk [163.1.2.165])
	by hypatia.math.ethz.ch (8.13.6/8.13.6) with ESMTP id l48CGvlW017056
	for <r-help@stat.math.ethz.ch>; Tue, 8 May 2007 14:16:57 +0200
Received: from smtp2.mail.ox.ac.uk ([163.1.2.205])
	by relay3.mail.ox.ac.uk with esmtp (Exim 4.62)
	(envelope-from <ramasamy@cancer.org.uk>)
	id 1HlOcj-0003qk-BP; Tue, 08 May 2007 13:16:57 +0100
Received: from dhcp-132.wolf.ox.ac.uk ([163.1.180.132] helo=[127.0.0.1])
	by smtp2.mail.ox.ac.uk with esmtpsa (TLSv1:AES256-SHA:256)
	(Exim 4.63) (envelope-from <ramasamy@cancer.org.uk>)
	id 1HlOcj-0004tN-7k; Tue, 08 May 2007 13:16:57 +0100
Message-ID: <46406A32.5080309@cancer.org.uk>
Date: Tue, 08 May 2007 13:16:50 +0100
From: Adaikalavan Ramasamy <ramasamy@cancer.org.uk>
User-Agent: Thunderbird 1.5.0.10 (Windows/20070221)
MIME-Version: 1.0
To: hadley wickham <h.wickham@gmail.com>
References: <f8e6ff050705080208w6e6892dfw9cdff386aa65d573@mail.gmail.com>
In-Reply-To: <f8e6ff050705080208w6e6892dfw9cdff386aa65d573@mail.gmail.com>
X-Oxford-Username: scro0777
X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
Cc: R Help <r-help@stat.math.ethz.ch>
Subject: Re: [R] Weighted least squares
X-BeenThere: r-help@stat.math.ethz.ch
X-Mailman-Version: 2.1.9
Precedence: list
List-Id: "Main R Mailing List: Primary help" <r-help.stat.math.ethz.ch>
List-Unsubscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
	<mailto:r-help-request@stat.math.ethz.ch?subject=unsubscribe>
List-Archive: <https://stat.ethz.ch/pipermail/r-help>
List-Post: <mailto:r-help@stat.math.ethz.ch>
List-Help: <mailto:r-help-request@stat.math.ethz.ch?subject=help>
List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
	<mailto:r-help-request@stat.math.ethz.ch?subject=subscribe>
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: 7bit
Sender: r-help-bounces@stat.math.ethz.ch
Errors-To: r-help-bounces@stat.math.ethz.ch

See below.

hadley wickham wrote:
> Dear all,
> 
> I'm struggling with weighted least squares, where something that I had
> assumed to be true appears not to be the case.  Take the following
> data set as an example:
> 
> df <- data.frame(x = runif(100, 0, 100))
> df$y <- df$x + 1 + rnorm(100, sd=15)
> 
> I had expected that:
> 
> summary(lm(y ~ x, data=df, weights=rep(2, 100)))
> summary(lm(y ~ x, data=rbind(df,df)))

You assign weights to different points according to some external 
quality or reliability measure not number of times the data point was 
measured.

Look at the estimates and standard error of the two models below:

  coefficients( summary(f.w <- lm(y ~ x, data=df, weights=rep(2, 100))) )
              Estimate Std. Error   t value     Pr(>|t|)
  (Intercept) 1.940765 3.30348066  0.587491 5.582252e-01
  x           0.982610 0.05893262 16.673448 2.264258e-30

  coefficients( summary( f.u <- lm(y ~ x, data=rbind(df,df) ) ) )
              Estimate Std. Error    t value     Pr(>|t|)
  (Intercept) 1.940765 2.32408609  0.8350659 4.046871e-01
  x           0.982610 0.04146066 23.6998165 1.012067e-59

You can see that they have same coefficient estimates but the second one 
  has smaller variances.

The repeated values artificially deflates the variance and thus inflates 
the precision. This is why you cannot treat replicate data as 
independent observations.


> would be equivalent, but they are not.  I suspect the difference is
> how the degrees of freedom is calculated - I had expected it to be
> sum(weights), but seems to be sum(weights > 0).  This seems
> unintuitive to me:
> 
> summary(lm(y ~ x, data=df, weights=rep(c(0,2), each=50)))
> summary(lm(y ~ x, data=df, weights=rep(c(0.01,2), each=50)))
> 
> What am I missing?  And what is the usual way to do a linear
> regression when you have aggregated data?

I would be best to use the individual data points instead of aggregated 
data as it allows you to estimate the within-group variations as well.

If you had individual data points, you could try something as follows. 
Please check the codes as I am no expert in the area of repeated measures.

  x  <- runif(100, 0, 100)
  y1 <- x + rnorm(100, mean=1, sd=15)
  y2 <- y1 + rnorm(100, sd=5)

  df <- data.frame( y=c(y1, y2),
                    x=c(x,x),
                    subject=factor(rep( paste("p", 1:100, sep=""), 2 ) ))

  library(nlme)
  summary( lme( y ~ x, random = ~ 1 | subject, data=df ) )

Try reading Pinheiro and Bates (http://tinyurl.com/yvvrr7) or related 
material for more information. Hope this helps.

> Thanks,
> 
> Hadley

Regards, Adai

______________________________________________
R-help@stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

