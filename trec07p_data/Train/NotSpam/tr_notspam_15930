From samba-technical-bounces+ktwarwic=speedy.uwaterloo.ca@lists.samba.org  Sun Jun  3 21:44:07 2007
Return-Path: <samba-technical-bounces+ktwarwic=speedy.uwaterloo.ca@lists.samba.org>
Received: from lists.samba.org (mail.samba.org [66.70.73.150])
	by flax9.uwaterloo.ca (8.12.8/8.12.5) with ESMTP id l541i6hB021835
	for <ktwarwic@speedy.uwaterloo.ca>; Sun, 3 Jun 2007 21:44:06 -0400
Received: from dp.samba.org (localhost [127.0.0.1])
	by lists.samba.org (Postfix) with ESMTP id 0DACD162AFA
	for <ktwarwic@speedy.uwaterloo.ca>; Mon,  4 Jun 2007 01:44:01 +0000 (GMT)
X-Spam-Checker-Version: SpamAssassin 3.1.7 (2006-10-05) on dp.samba.org
X-Spam-Level: 
X-Spam-Status: No, score=-4.1 required=3.8 tests=BAYES_00,SPF_PASS 
	autolearn=ham version=3.1.7
X-Original-To: samba-technical@samba.org
Delivered-To: samba-technical@samba.org
Received: from wa-out-1112.google.com (wa-out-1112.google.com [209.85.146.180])
	by lists.samba.org (Postfix) with ESMTP id C4461162AF7
	for <samba-technical@samba.org>; Mon,  4 Jun 2007 01:43:02 +0000 (GMT)
Received: by wa-out-1112.google.com with SMTP id m34so1609187wag
	for <samba-technical@samba.org>; Sun, 03 Jun 2007 18:43:02 -0700 (PDT)
DKIM-Signature: a=rsa-sha1; c=relaxed/relaxed; d=gmail.com; s=beta;
	h=domainkey-signature:received:received:message-id:date:from:to:subject:cc:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;
	b=Yn5kvtBt2JMSLdoKzuHKz9Af5IbEbBO/sWP1lRYV/YpIIMVZXAVwIoaOwmvhtYKzbc0mdGGXUByaa6nz6GPXJj5DnEcg8xoPMObTUVwIq5Y9lCMwjAJ990pknGf2n00ealpSM1EQPT046DlRIBHmwDM4PlkxR9/Z6OOYgMSRfK0=
DomainKey-Signature: a=rsa-sha1; c=nofws; d=gmail.com; s=beta;
	h=received:message-id:date:from:to:subject:cc:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;
	b=oRQJnQboUNfReoezwXWUaPT3pajN74Hu6L0jLsKXWFunxTBQvn2014XrGXz6J42SYYQgyiuPx1WzAEfpG5ri8CODU0Pzg+Ok8TzIIbFhyMWs0YLFblJ/EcSRujcH4xv/zPcGhIunA2A7Y4VIpm+N85Gjl+Epn2six2wbcLbdYOQ=
Received: by 10.115.77.1 with SMTP id e1mr4284171wal.1180921382109;
	Sun, 03 Jun 2007 18:43:02 -0700 (PDT)
Received: by 10.114.74.14 with HTTP; Sun, 3 Jun 2007 18:43:02 -0700 (PDT)
Message-ID: <c9a3e4540706031843s300fd456vdd762967b3528aa7@mail.gmail.com>
Date: Mon, 4 Jun 2007 01:43:02 +0000
From: "ronnie sahlberg" <ronniesahlberg@gmail.com>
To: "Christopher R. Hertel" <crh@ubiqx.mn.org>
In-Reply-To: <4663608B.3040103@ubiqx.mn.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
Content-Disposition: inline
References: <517eb05c0705271430q471246a9jac9cd62775dafc2c@mail.gmail.com>
	<18010.6363.787216.619457@samba.org>
	<517eb05c0705271903k720873a1hee666908f8977e00@mail.gmail.com>
	<465A51D4.70503@ubiqx.mn.org>
	<c9a3e4540706030001m1499fd91ub98b2b097de195@mail.gmail.com>
	<466312ED.3060309@ubiqx.mn.org> <18019.13041.277110.609886@samba.org>
	<4663608B.3040103@ubiqx.mn.org>
Cc: tridge@samba.org, samba-technical@samba.org
Subject: Re: first swipe at ctdb spec file
X-BeenThere: samba-technical@lists.samba.org
X-Mailman-Version: 2.1.5
Precedence: list
List-Id: "Discussions on Samba internals. For general questions please
	subscribe to the list samba@samba.org"
	<samba-technical.lists.samba.org>
List-Unsubscribe: <https://lists.samba.org/mailman/listinfo/samba-technical>, 
	<mailto:samba-technical-request@lists.samba.org?subject=unsubscribe>
List-Archive: <http://lists.samba.org/archive/samba-technical>
List-Post: <mailto:samba-technical@lists.samba.org>
List-Help: <mailto:samba-technical-request@lists.samba.org?subject=help>
List-Subscribe: <https://lists.samba.org/mailman/listinfo/samba-technical>,
	<mailto:samba-technical-request@lists.samba.org?subject=subscribe>
Sender: samba-technical-bounces+ktwarwic=speedy.uwaterloo.ca@lists.samba.org
Errors-To: samba-technical-bounces+ktwarwic=speedy.uwaterloo.ca@lists.samba.org

There is currently no pCIFS   so I "took" the name. :-)
It is obvioulsy a play on the pNFS acronym which is incredibly hyped.



pCIFS in this context means a load-sharing cluster where multiple
nodes export the same data read-write to a cluster.


This is similar to pNFS, however pNFS is not really clustered, instead
(since it is much easier) pNFS provides scalability by having only one
node that exports tha share and processes all the metadata operations,
and then to provide "scalability" it provides a mapping between file
data and storage so that clients can do file i/o directly to storage
bypassing the nfs server completely.
And thus reducing the workload on the, single, NFS server, providing
higher scalability than if the singler NFS server also had to process
the data.

While it would be possible and likely a superior solution for pNFS to
provide real read-write clustering across multiple nas heads in a
cluster,   that is more difficult and not the path that the IETF
workgroup has taken.

One way of looking at the common pNFS is that is is really just a
single server  but it provides some additional extensions in order to
reduce the amount of data that is passed across the interconnect
between the nfs server and the storage backend.
NFS servers are often more limited by the bandwidth of the SAN
interconnect than CPU or memory in the nas head itself.
Thus it is primarily a solution to reduce SAN utilization and
saturation that occurs rather than providing a clustered service.


It would certainly be possible, academically speaking, to build a
pCIFS implementation similar to the pNFS path  with only one single
node that runs samba and then letting all clients do i/o based on some
mapping protocol that maps between files and extents on a storage
device.
Howver,   that is really just a "quick fix" to get slightly better
than single node performance on a nas head.


a true read-write cluster like our pCIFS   and a proper pNFS
implementation would be vastly superiour to the path currently taken
by pNFS workgroup, but also much harder to imlement.


Comparasions between our pCIFS and the most common pNFS approach :
 * higher scalability. we distribute also metadata operations across
the different nodes in the cluster.
 * higher availability, we do not have a single point of failure (no
single metadata server)
 * much higher performance.   There is a cost associated with a file
mapping protocol which is non-zero   and history has shown that for
these "pNFS" implementations (there are several, some of which have
been in production use for many many years).
In many implementations this "cost" of filemapping means that one only
gets any real benefit for the case where one only works with doing
sequential access to very large files.


please try it out.
it is pretty cool stuff.


On 6/4/07, Christopher R. Hertel <crh@ubiqx.mn.org> wrote:
> tridge@samba.org wrote:
> > Chris,
> >
> >  > Quick question:  is this the pCIFS that Peter Brahm started working on
> a few
> >  > years back or something different?
> >
> > I've no idea what Peter worked on.
>
> Have you had a chance to look at pNFS (which is in the NFSv4.1 spec.)?
>
> A few years ago, Peter proposed a complimentary pCIFS which would allow
> clients direct access to the block storage.  Metadata management would be
> handled via CIFS but the clients, once they held an appropriate lock, would
> do direct block I/O (via iSCSI, Fibre Channel, or other methods).
>
> I was speaking with folks from Panasas a couple of weeks ago.  Garth gave a
> pNFS presentation and afterwards we started talking about the flexibility of
> the Linux implementation of pNFS, and the possibility that the client-side
> code could also be used to support pCIFS functionality.  The Panasas folks
> sounded interested, but I think they'd want to know more about the
> possibility of follow-through from both Samba and the Linux CIFS VFS client.
>
> So back to my question:  When Ronnie talks about pCIFS which pCIFS is that
> and what is it intended to do?  Do we have a collision in the name space or
> is someone (not unusually) way ahead of me?
>
> >  > I'm interested in the API at present.
> >
> > The API is there, but the client half of it (which is what you would
> > use) is not yet cleanly separated from the server. I've started doing
> > that, but it will take some time yet.
> >
> > We'll end up with a libctdb library, which is what applications will
> > use. The code in common/ctdb_client.c is the basis for that library.
>
> I will take a look.
>
> Thanks.
>
> Chris -)-----
>
> --
> "Implementing CIFS - the Common Internet FileSystem" ISBN: 013047116X
> Samba Team -- http://www.samba.org/     -)-----   Christopher R. Hertel
> jCIFS Team -- http://jcifs.samba.org/   -)-----   ubiqx development, uninq.
> ubiqx Team -- http://www.ubiqx.org/     -)-----   crh@ubiqx.mn.org
> OnLineBook -- http://ubiqx.org/cifs/    -)-----   crh@ubiqx.org
>

